{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PES 2020 Players Dataset Collection (from http://pesdb.net/pes2020) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation:\n",
    "    \n",
    "    As a soccer fan, I am crazy for soccer video games (especially FIFA and PES). I spent a lot of time on playing these games to kill time and practice the new strategies virtually. As I went to college, sports analytics became one of the areas that I am interested in. As I felt more determined to go deep into data, I would like to strat a project considering the rate of each player in a game and see how the factors determine the overall ratings. \n",
    "\n",
    "## Major Techniques:\n",
    "    \n",
    "    - Pandas\n",
    "    - BeautifulSoups\n",
    "    - TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection:\n",
    "   **The first step is to create a dataframe that hold all the data.**\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This is the major data framework.\n",
    "# You ONLY need to run this following code for the first time\n",
    "\n",
    "df = pd.DataFrame(columns=('Name','Height','Weight','Age','Position','Offensive Awareness','Ball Control','Dribbling','Tight Possession',\n",
    "                           'Low Pass','Lofted Pass','Finishing','Heading','Place Kicking','Curl','Speed','Acceleration','Kicking Power',\n",
    "                           'Jump','Physical Contact','Balance','Stamina','Defensive Awareness','Ball Winning','Aggression','GK Awareness',\n",
    "                           'GK Catching','GK Clearing','GK Reflexes','GK Reach','Weak Foot Usage','Weak Foot Accuracy','Form',\n",
    "                           'Injury Resistance','Overall Rating'))\n",
    "\n",
    "df.to_excel(r\"C:\\Users\\qiuwk\\Google Drive\\Projects\\PES.xlsx\") # Change the path to where you want it to be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **_The following program is to create a list of players' ID so that we can access each player's profile._**\n",
    "   \n",
    "   **Note**: The website prevents me from requesting too often (I think that's a protection for web-scraping), so I can set a  \"sleeping\" time of about 2 minutes for every ten visites to the website. But I defintely want to see a better solution :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import time\n",
    "\n",
    "id_list = []\n",
    "count = 0\n",
    "\n",
    "base_url = 'http://pesdb.net/pes2020'\n",
    " \n",
    "for i in range(471):\n",
    "    url = base_url + '/?page=' + str(i+1)\n",
    "    html = urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, features = 'lxml')\n",
    "    id_source = soup.find_all(\"a\", href= re.compile(\"^\\./\\?id=\\d+\"))\n",
    "    for j in id_source:\n",
    "        id_list.append(j.get('href'))\n",
    "    count += 1\n",
    "    print(i)\n",
    "    if count == 10:\n",
    "        time.sleep(115)\n",
    "        count = 0\n",
    "\n",
    "# Lastly, I will save my ID list to a local spreadsheet.\n",
    "df_2 = pd.DataFrame(data = id_list, columns = 'ID')\n",
    "df_2.to_excel(r\"C:\\Users\\qiuwk\\Google Drive\\Projects\\PES_tem.xlsx\") # Change the path to where you want it to be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_After getting the IDs, I will use the IDs to access the corresponding players' profiles. \n",
    "\n",
    "**Note**: for some columns, I was not able to scrap by using Regex. Consequently, results for \"age\" and \"position\" were not accurate and my scrapping was interruptted several times after reading hundreds of players. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import time\n",
    "\n",
    "df = pd.read_excel(r\"C:\\Users\\qiuwk\\Google Drive\\Projects\\PES.xlsx\") # Adjust the path\n",
    "df_2 = pd.read_excel(r\"C:\\Users\\qiuwk\\Google Drive\\Projects\\PES_tem.xlsx\") # Adjust the path\n",
    "id_list = list(df_2['ID'])\n",
    "\n",
    "error_list = []\n",
    "\n",
    "count = 0\n",
    "base_url = 'http://pesdb.net/pes2020'\n",
    "\n",
    "for i in id_list:\n",
    "    url = base_url + i[1:]\n",
    "    print(url)\n",
    "    html = urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, features = 'lxml')\n",
    "    \n",
    "    result = soup.find_all(\"td\")\n",
    "    data = [str(result[1])[4:-5],str(result[7])[4:-5],str(result[8])[4:-5],str(result[9])[4:-5]]\n",
    "    \n",
    "    raw_position = str(result[12])\n",
    "    test = re.search(r\">(\\w+)</div\",raw_position)\n",
    "    \n",
    "    # the code was interrupted due a dismatch of position, so I did a test here and try to adjust the data later\n",
    "    \n",
    "    if test is None:\n",
    "        position = 0\n",
    "    else:    \n",
    "        re.search(r\">(\\w+)</div\",raw_position).group(1)\n",
    "        \n",
    "    data.append(position)\n",
    "    \n",
    "    for j in range(25):\n",
    "        ID = 'a'+str(j)\n",
    "        AClass_result = str(soup.find(id=ID))\n",
    "        data.append(re.search(r\">(\\d+)<\"\",AClass_result).group(1)) \n",
    "        \n",
    "    for k in range(42,46):\n",
    "        number = str(result[k])\n",
    "        data.append(number[-6])\n",
    "                              \n",
    "    last_one = str(soup.find(id='a25'))\n",
    "    data.append(re.search(r'>(\\d+)<',last_one).group(1))\n",
    "    \n",
    "    df.loc[id_list.index(i)+1] = data\n",
    "    print(data)\n",
    "    \n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        time.sleep(115)\n",
    "        count = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here, I export the data separatly since I want to make sure my results are mostly accurate.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I hid the second line first to check df before writing it into a new spreadsheet\n",
    "df \n",
    "\n",
    "df.to_excel(r\"C:\\Users\\qiuwk\\Google Drive\\Projects\\PES_1.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I realized that I can go to the pages where I retrived IDs to get the positions. So I did that to fill out the \"zeros\" in my spreadsheet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import time\n",
    "\n",
    "position_list = []\n",
    "count = 0\n",
    "for i in range(1,471):\n",
    "    html = urlopen('http://pesdb.net/pes2020/?page=' + str(i)).read()\n",
    "    soup = BeautifulSoup(html, features = 'lxml')\n",
    "    raw = soup.find_all(class_ = re.compile(\"pos[A-Z][A-Z]\"))\n",
    "    for j in raw:\n",
    "        position = re.search(r'>([A-Z][A-Z][A-Z]?)</div',str(j)).group(1)\n",
    "        position_list.append(position)\n",
    "    count +=1\n",
    "    if count == 10:\n",
    "        time.sleep(115)\n",
    "        count = 0\n",
    "    print(i)\n",
    "    \n",
    "df_position = pd.DataFrame(position_list)\n",
    "df_position.to_excel(r\"C:\\Users\\qiuwk\\Google Drive\\Projects\\position.xlsx\") # Change the path to where you want it to be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I realized there are some mismatches of \"height\", \"weight\", \"age.\" So, I firstly used filter function to move the \"weight\" and \"age\" column to the correct positions. Then, I run the following codes to scrap the height again.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import time\n",
    "\n",
    "height_list = []\n",
    "count = 0\n",
    "for i in range (1,471):\n",
    "    html = urlopen('http://pesdb.net/pes2020/?page=' + str(i)).read()\n",
    "    soup = BeautifulSoup(html, features = 'lxml')\n",
    "    raw = soup.find_all(\"td\")\n",
    "    for j in raw:\n",
    "        result = re.search(\"<td>[0-9][0-9][0-9]</td>\",str(j))\n",
    "        if result is not None:\n",
    "            result_int = int(re.search(\"^<td>([0-9][0-9][0-9])</td>$\",str(j)).group(1))\n",
    "            if result_int > 130:\n",
    "                height_list.append(re.search(\"^<td>([0-9][0-9][0-9])</td>$\",str(j)).group(1))\n",
    "   \n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        time.sleep(115)\n",
    "        count = 0\n",
    "        \n",
    "    print(i)\n",
    "    \n",
    "df_height = pd.DataFrame(height_list)\n",
    "df_height.to_excel(r\"C:\\Users\\qiuwk\\Google Drive\\Projects\\height.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Luckily, as I checked my data, I could did some manual work to fix them.** (It is stupid...but forgive me as a beginner...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion & Mistakes\n",
    "\n",
    "    From knowing nothing, I spent approximately two weeks to complete the data collection. This database is very organized, but there is still some works to modify the scraped data. My next step will be to perform analysis, majorly multi-regression analysis, to figure out how PES evaluates a player given all the breakdowns. \n",
    "    \n",
    "    For improvement, I would like to that "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
